{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Language_Model.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "nscCK66C02rk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c3ad1d3c-0706-430a-90db-27106c47242a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "import nltk\n",
        "import re\n",
        "import os\n",
        "import array\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras \n",
        "from keras.callbacks import ModelCheckpoint,EarlyStopping\n",
        "from keras.utils import np_utils\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.layers import Embedding, LSTM, Dense, Dropout,GRU\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.models import Sequential\n",
        "from nltk.tokenize import word_tokenize\n",
        "from pickle import dump\n",
        "from keras.utils.np_utils import to_categorical\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
        "\n",
        "nltk.download('punkt')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def tokenize(data):\n",
        "  tokens = re.sub(r'[,!?;-]+', '.', data)\n",
        "  tokens = nltk.word_tokenize(tokens)  # tokenize string to words\n",
        "  tokens = [ ch.lower() for ch in tokens if ch.isalpha() or ch == '.'] #Check if all the characters in the text are letters\n",
        "  return tokens\n",
        "\n",
        "def Create_tokens(filename): \n",
        "  file = open(filename, 'r')\n",
        "  text = file.read()\n",
        "  token = tokenize(text)\n",
        "  file.close()\n",
        "  return token"
      ],
      "metadata": {
        "id": "ppUpW5LCFNHa"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Note: Train size is too small , for better result provide large data for training"
      ],
      "metadata": {
        "id": "IOCZLBygguEF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_token= Create_tokens('train.europarl')\n",
        "val_token= Create_tokens('dev.europarl')\n",
        "test_token= Create_tokens('test.europarl')\n",
        "# train_token= Create_tokens('train.fr')\n",
        "# val_token= Create_tokens('dev.fr')\n",
        "# test_token= Create_tokens('test.fr')\n",
        "total_tokens = []\n",
        "total_tokens.extend(train_token)\n",
        "total_tokens.extend(val_token)\n",
        "total_tokens.extend(test_token)\n",
        "total_tokens.extend(['unk'])\n",
        "vocab = sorted(list(set(total_tokens)))"
      ],
      "metadata": {
        "id": "lxUIxKstIbTn"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(total_tokens[:20])\n",
        "print('Total Tokens: %d' % len(total_tokens))\n",
        "print('Unique Tokens: %d' % len(vocab))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MWllzlalK1UU",
        "outputId": "47f32582-afec-48b1-c5fd-4cf558b235cd"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['resumption', 'of', 'the', 'session', 'i', 'declare', 'resumed', 'the', 'session', 'of', 'the', 'european', 'parliament', 'adjourned', 'on', 'friday', 'december', 'and', 'i', 'would']\n",
            "Total Tokens: 98353\n",
            "Unique Tokens: 6061\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def word2Index(total_tokens,vocab):\n",
        "  idx = 0\n",
        "  word2Ind = dict()\n",
        "  for w in vocab:\n",
        "    word2Ind[w]=idx\n",
        "    idx+=1\n",
        "  return word2Ind\n",
        "\n",
        "word2Ind = word2Index(total_tokens,vocab)\n",
        "len(word2Ind)"
      ],
      "metadata": {
        "id": "zvSgxDCUJ0yu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "08c4b9e3-0bdd-4f7b-dae9-d6fdc90e0ff6"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "6061"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "w2I = open('word2Index', 'wb')\n",
        "pickle.dump(word2Ind,w2I)\n",
        "w2I.close()"
      ],
      "metadata": {
        "id": "I61AkNRVZHHQ"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def Seq_of_Tokens(tokens,vocab,word2Ind):\n",
        " length = 11\n",
        " sequences,X,y=list(),list(),list()\n",
        " \n",
        " for i in range(length, len(tokens)):\n",
        "\t seq = tokens[i-length:i] # select sequence of tokens\n",
        "\t temp_x,temp_y=list(),list()\n",
        "\t temp_y.append(word2Ind[seq[-1]])\n",
        "\t \n",
        "\t for i in range(0,length-1):\n",
        "\t\t temp_x.append(word2Ind[seq[i]])\n",
        "\t line = ' '.join(seq) # convert into a line\n",
        "\t sequences.append(line) # store\n",
        "\t X.append(temp_x)\n",
        "\t y.append(temp_y)\n",
        " return sequences,np.array(X),np.array(y) "
      ],
      "metadata": {
        "id": "O6QXyTDxHvTL"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_seq,X_train,y_train = Seq_of_Tokens(train_token,vocab,word2Ind)\n",
        "val_seq,X_val,y_val = Seq_of_Tokens(val_token,vocab,word2Ind)\n",
        "test_seq,X_test,y_test = Seq_of_Tokens(test_token,vocab,word2Ind)\n",
        "seq_length = X_train.shape[1]\n",
        "vocab_size = len(vocab)"
      ],
      "metadata": {
        "id": "SrOjQwa9K-_t"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"############# TRAIN ################\\n\")\n",
        "print(\"train sequences : \",train_seq[:10])\n",
        "print(\"train data features : \",X_train[:10])\n",
        "print(\"train data labels : \",y_train[:10])\n",
        "print(X_train.shape,y_train.shape,'\\n')\n",
        "\n",
        "print(\"############# VAL ################\\n\")\n",
        "print(\"Val sequences : \",val_seq[:10])\n",
        "print(\"Val data features : \",X_val[:10])\n",
        "print(\"Val data labels : \",y_val[:10])\n",
        "print(X_val.shape,y_val.shape,'\\n')\n",
        "\n",
        "print(\"############# TEST ################\\n\")\n",
        "print(\"Test sequences : \",test_seq[:10])\n",
        "print(\"Test data features : \",X_test[:10])\n",
        "print(\"Test data labels : \",y_test[:10])\n",
        "print(X_test.shape,y_test.shape,'\\n')"
      ],
      "metadata": {
        "id": "xC97xcfaRVuY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "224386c0-743b-4081-9840-0563602d14ec"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "############# TRAIN ################\n",
            "\n",
            "train sequences :  ['resumption of the session i declare resumed the session of the', 'of the session i declare resumed the session of the european', 'the session i declare resumed the session of the european parliament', 'session i declare resumed the session of the european parliament adjourned', 'i declare resumed the session of the european parliament adjourned on', 'declare resumed the session of the european parliament adjourned on friday', 'resumed the session of the european parliament adjourned on friday december', 'the session of the european parliament adjourned on friday december and', 'session of the european parliament adjourned on friday december and i', 'of the european parliament adjourned on friday december and i would']\n",
            "train data features :  [[4668 3696 5432 4879 2680 1363 4667 5432 4879 3696]\n",
            " [3696 5432 4879 2680 1363 4667 5432 4879 3696 5432]\n",
            " [5432 4879 2680 1363 4667 5432 4879 3696 5432 1960]\n",
            " [4879 2680 1363 4667 5432 4879 3696 5432 1960 3849]\n",
            " [2680 1363 4667 5432 4879 3696 5432 1960 3849  122]\n",
            " [1363 4667 5432 4879 3696 5432 1960 3849  122 3725]\n",
            " [4667 5432 4879 3696 5432 1960 3849  122 3725 2357]\n",
            " [5432 4879 3696 5432 1960 3849  122 3725 2357 1349]\n",
            " [4879 3696 5432 1960 3849  122 3725 2357 1349  276]\n",
            " [3696 5432 1960 3849  122 3725 2357 1349  276 2680]]\n",
            "train data labels :  [[5432]\n",
            " [1960]\n",
            " [3849]\n",
            " [ 122]\n",
            " [3725]\n",
            " [2357]\n",
            " [1349]\n",
            " [ 276]\n",
            " [2680]\n",
            " [6023]]\n",
            "(58202, 10) (58202, 1) \n",
            "\n",
            "############# VAL ################\n",
            "\n",
            "Val sequences :  ['it is this tendency which presents a problem right now .', 'is this tendency which presents a problem right now . much', 'this tendency which presents a problem right now . much more', 'tendency which presents a problem right now . much more than', 'which presents a problem right now . much more than the', 'presents a problem right now . much more than the scale', 'a problem right now . much more than the scale of', 'problem right now . much more than the scale of the', 'right now . much more than the scale of the epidemic', 'now . much more than the scale of the epidemic in']\n",
            "Val data features :  [[3023 3012 5457 5400 5947 4099    1 4158 4703 3652]\n",
            " [3012 5457 5400 5947 4099    1 4158 4703 3652    0]\n",
            " [5457 5400 5947 4099    1 4158 4703 3652    0 3540]\n",
            " [5400 5947 4099    1 4158 4703 3652    0 3540 3522]\n",
            " [5947 4099    1 4158 4703 3652    0 3540 3522 5426]\n",
            " [4099    1 4158 4703 3652    0 3540 3522 5426 5432]\n",
            " [   1 4158 4703 3652    0 3540 3522 5426 5432 4784]\n",
            " [4158 4703 3652    0 3540 3522 5426 5432 4784 3696]\n",
            " [4703 3652    0 3540 3522 5426 5432 4784 3696 5432]\n",
            " [3652    0 3540 3522 5426 5432 4784 3696 5432 1917]]\n",
            "Val data labels :  [[   0]\n",
            " [3540]\n",
            " [3522]\n",
            " [5426]\n",
            " [5432]\n",
            " [4784]\n",
            " [3696]\n",
            " [5432]\n",
            " [1917]\n",
            " [2755]]\n",
            "(12689, 10) (12689, 1) \n",
            "\n",
            "############# TEST ################\n",
            "\n",
            "Test sequences :  ['when used preventively . it saves the state and the economy', 'used preventively . it saves the state and the economy a', 'preventively . it saves the state and the economy a great', '. it saves the state and the economy a great deal', 'it saves the state and the economy a great deal of', 'saves the state and the economy a great deal of money', 'the state and the economy a great deal of money .', 'state and the economy a great deal of money . i', 'and the economy a great deal of money . i have', 'the economy a great deal of money . i have completely']\n",
            "Test data features :  [[5940 5767 4124    0 3023 4777 5432 5130  276 5432]\n",
            " [5767 4124    0 3023 4777 5432 5130  276 5432 1749]\n",
            " [4124    0 3023 4777 5432 5130  276 5432 1749    1]\n",
            " [   0 3023 4777 5432 5130  276 5432 1749    1 2474]\n",
            " [3023 4777 5432 5130  276 5432 1749    1 2474 1333]\n",
            " [4777 5432 5130  276 5432 1749    1 2474 1333 3696]\n",
            " [5432 5130  276 5432 1749    1 2474 1333 3696 3508]\n",
            " [5130  276 5432 1749    1 2474 1333 3696 3508    0]\n",
            " [ 276 5432 1749    1 2474 1333 3696 3508    0 2680]\n",
            " [5432 1749    1 2474 1333 3696 3508    0 2680 2555]]\n",
            "Test data labels :  [[1749]\n",
            " [   1]\n",
            " [2474]\n",
            " [1333]\n",
            " [3696]\n",
            " [3508]\n",
            " [   0]\n",
            " [2680]\n",
            " [2555]\n",
            " [ 994]]\n",
            "(27428, 10) (27428, 1) \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 1000\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices((X_train,y_train))\n",
        "train_dataset = train_dataset.shuffle(buffer_size=1024).batch(batch_size)"
      ],
      "metadata": {
        "id": "sZUD3TMzcYEN"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "model.add(Embedding(vocab_size, 50, input_length=seq_length))\n",
        "model.add(LSTM(100, return_sequences=True))\n",
        "model.add(LSTM(100))\n",
        "model.add(Dense(100, activation='relu'))\n",
        "model.add(Dense(vocab_size, activation='softmax'))\n",
        "print(model.summary())"
      ],
      "metadata": {
        "id": "SzuAa__P50u_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7be2bbbe-2867-43b6-e768-8cccb8adb9aa"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       (None, 10, 50)            303050    \n",
            "                                                                 \n",
            " lstm (LSTM)                 (None, 10, 100)           60400     \n",
            "                                                                 \n",
            " lstm_1 (LSTM)               (None, 100)               80400     \n",
            "                                                                 \n",
            " dense (Dense)               (None, 100)               10100     \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 6061)              612161    \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,066,111\n",
            "Trainable params: 1,066,111\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Y_val = to_categorical(y_val,num_classes=vocab_size)\n",
        "def Train_model(model,name,train_dataset,vocab_size,X_val,Y_val):\n",
        "  for step,(X_batch_train,y_batch_train) in enumerate(train_dataset):\n",
        "    y_t=to_categorical(y_batch_train,num_classes=vocab_size)\n",
        "    model.fit(X_batch_train,y_t,epochs=1,verbose=2,validation_data=(X_val, Y_val))\n",
        "  return model"
      ],
      "metadata": {
        "id": "E6viSAWjLRav"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "model = Train_model(model,'euro',train_dataset,vocab_size,X_val,Y_val)"
      ],
      "metadata": {
        "id": "SC4wySFwPk29",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5528f86a-dd3f-42a2-c65d-3ef96038f696"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "32/32 - 11s - loss: 5.7844 - accuracy: 0.0890 - val_loss: 6.7419 - val_accuracy: 0.0878 - 11s/epoch - 334ms/step\n",
            "32/32 - 6s - loss: 5.9003 - accuracy: 0.0890 - val_loss: 6.9253 - val_accuracy: 0.0878 - 6s/epoch - 172ms/step\n",
            "32/32 - 5s - loss: 6.0486 - accuracy: 0.1010 - val_loss: 6.7808 - val_accuracy: 0.0878 - 5s/epoch - 171ms/step\n",
            "32/32 - 5s - loss: 6.4532 - accuracy: 0.0940 - val_loss: 6.6251 - val_accuracy: 0.0878 - 5s/epoch - 170ms/step\n",
            "32/32 - 5s - loss: 6.2742 - accuracy: 0.0970 - val_loss: 6.5056 - val_accuracy: 0.0878 - 5s/epoch - 172ms/step\n",
            "32/32 - 5s - loss: 6.1181 - accuracy: 0.0980 - val_loss: 6.4529 - val_accuracy: 0.0878 - 5s/epoch - 169ms/step\n",
            "32/32 - 6s - loss: 6.1443 - accuracy: 0.0830 - val_loss: 6.4296 - val_accuracy: 0.0878 - 6s/epoch - 175ms/step\n",
            "32/32 - 6s - loss: 6.1259 - accuracy: 0.0920 - val_loss: 6.3778 - val_accuracy: 0.0878 - 6s/epoch - 175ms/step\n",
            "32/32 - 6s - loss: 6.2174 - accuracy: 0.0900 - val_loss: 6.3367 - val_accuracy: 0.0878 - 6s/epoch - 176ms/step\n",
            "32/32 - 8s - loss: 6.2264 - accuracy: 0.0980 - val_loss: 6.3148 - val_accuracy: 0.0878 - 8s/epoch - 250ms/step\n",
            "32/32 - 7s - loss: 6.0319 - accuracy: 0.0780 - val_loss: 6.3229 - val_accuracy: 0.0878 - 7s/epoch - 207ms/step\n",
            "32/32 - 6s - loss: 6.1300 - accuracy: 0.0840 - val_loss: 6.3047 - val_accuracy: 0.0878 - 6s/epoch - 174ms/step\n",
            "32/32 - 6s - loss: 6.0922 - accuracy: 0.0890 - val_loss: 6.2773 - val_accuracy: 0.0878 - 6s/epoch - 179ms/step\n",
            "32/32 - 6s - loss: 6.1188 - accuracy: 0.0790 - val_loss: 6.2818 - val_accuracy: 0.0878 - 6s/epoch - 177ms/step\n",
            "32/32 - 6s - loss: 5.9727 - accuracy: 0.0930 - val_loss: 6.2754 - val_accuracy: 0.0878 - 6s/epoch - 175ms/step\n",
            "32/32 - 6s - loss: 5.8509 - accuracy: 0.1110 - val_loss: 6.3919 - val_accuracy: 0.0878 - 6s/epoch - 177ms/step\n",
            "32/32 - 6s - loss: 5.7968 - accuracy: 0.1030 - val_loss: 6.2987 - val_accuracy: 0.0878 - 6s/epoch - 174ms/step\n",
            "32/32 - 6s - loss: 5.8513 - accuracy: 0.1050 - val_loss: 6.3157 - val_accuracy: 0.0878 - 6s/epoch - 181ms/step\n",
            "32/32 - 6s - loss: 5.9802 - accuracy: 0.0860 - val_loss: 6.3288 - val_accuracy: 0.0901 - 6s/epoch - 183ms/step\n",
            "32/32 - 6s - loss: 5.9160 - accuracy: 0.1020 - val_loss: 6.3379 - val_accuracy: 0.1037 - 6s/epoch - 175ms/step\n",
            "32/32 - 6s - loss: 6.0674 - accuracy: 0.1100 - val_loss: 6.2841 - val_accuracy: 0.0961 - 6s/epoch - 190ms/step\n",
            "32/32 - 6s - loss: 5.8043 - accuracy: 0.1120 - val_loss: 6.2709 - val_accuracy: 0.1018 - 6s/epoch - 179ms/step\n",
            "32/32 - 6s - loss: 5.8441 - accuracy: 0.1260 - val_loss: 6.3366 - val_accuracy: 0.1047 - 6s/epoch - 175ms/step\n",
            "32/32 - 6s - loss: 5.8857 - accuracy: 0.1130 - val_loss: 6.3176 - val_accuracy: 0.0917 - 6s/epoch - 180ms/step\n",
            "32/32 - 6s - loss: 5.8759 - accuracy: 0.1340 - val_loss: 6.2382 - val_accuracy: 0.1051 - 6s/epoch - 198ms/step\n",
            "32/32 - 6s - loss: 5.9117 - accuracy: 0.1290 - val_loss: 6.2835 - val_accuracy: 0.1080 - 6s/epoch - 182ms/step\n",
            "32/32 - 6s - loss: 5.9044 - accuracy: 0.1420 - val_loss: 6.2284 - val_accuracy: 0.1064 - 6s/epoch - 176ms/step\n",
            "32/32 - 6s - loss: 6.1198 - accuracy: 0.1100 - val_loss: 6.2185 - val_accuracy: 0.1039 - 6s/epoch - 177ms/step\n",
            "32/32 - 6s - loss: 6.1253 - accuracy: 0.1200 - val_loss: 6.2350 - val_accuracy: 0.1107 - 6s/epoch - 178ms/step\n",
            "32/32 - 6s - loss: 5.9868 - accuracy: 0.1130 - val_loss: 6.2103 - val_accuracy: 0.1069 - 6s/epoch - 178ms/step\n",
            "32/32 - 6s - loss: 6.0683 - accuracy: 0.1390 - val_loss: 6.2005 - val_accuracy: 0.1086 - 6s/epoch - 173ms/step\n",
            "32/32 - 6s - loss: 5.9726 - accuracy: 0.1410 - val_loss: 6.2028 - val_accuracy: 0.1091 - 6s/epoch - 196ms/step\n",
            "32/32 - 6s - loss: 5.8555 - accuracy: 0.1290 - val_loss: 6.1821 - val_accuracy: 0.1095 - 6s/epoch - 182ms/step\n",
            "32/32 - 6s - loss: 5.8709 - accuracy: 0.1280 - val_loss: 6.1929 - val_accuracy: 0.1104 - 6s/epoch - 174ms/step\n",
            "32/32 - 6s - loss: 5.9441 - accuracy: 0.1110 - val_loss: 6.2181 - val_accuracy: 0.1069 - 6s/epoch - 173ms/step\n",
            "32/32 - 6s - loss: 5.8895 - accuracy: 0.1280 - val_loss: 6.2436 - val_accuracy: 0.1091 - 6s/epoch - 174ms/step\n",
            "32/32 - 6s - loss: 5.7865 - accuracy: 0.1400 - val_loss: 6.2097 - val_accuracy: 0.1103 - 6s/epoch - 176ms/step\n",
            "32/32 - 7s - loss: 5.9814 - accuracy: 0.1410 - val_loss: 6.2151 - val_accuracy: 0.1117 - 7s/epoch - 205ms/step\n",
            "32/32 - 7s - loss: 6.0469 - accuracy: 0.1210 - val_loss: 6.1855 - val_accuracy: 0.1126 - 7s/epoch - 229ms/step\n",
            "32/32 - 12s - loss: 5.6424 - accuracy: 0.1610 - val_loss: 6.2625 - val_accuracy: 0.1147 - 12s/epoch - 361ms/step\n",
            "32/32 - 7s - loss: 5.8205 - accuracy: 0.1440 - val_loss: 6.2046 - val_accuracy: 0.1154 - 7s/epoch - 205ms/step\n",
            "32/32 - 6s - loss: 5.8394 - accuracy: 0.1360 - val_loss: 6.2100 - val_accuracy: 0.1135 - 6s/epoch - 187ms/step\n",
            "32/32 - 6s - loss: 5.8283 - accuracy: 0.1420 - val_loss: 6.1748 - val_accuracy: 0.1149 - 6s/epoch - 187ms/step\n",
            "32/32 - 6s - loss: 5.9234 - accuracy: 0.1180 - val_loss: 6.1593 - val_accuracy: 0.1129 - 6s/epoch - 182ms/step\n",
            "32/32 - 7s - loss: 5.6316 - accuracy: 0.1380 - val_loss: 6.2064 - val_accuracy: 0.1126 - 7s/epoch - 209ms/step\n",
            "32/32 - 6s - loss: 5.7340 - accuracy: 0.1460 - val_loss: 6.2272 - val_accuracy: 0.1167 - 6s/epoch - 182ms/step\n",
            "32/32 - 7s - loss: 5.8145 - accuracy: 0.1330 - val_loss: 6.2423 - val_accuracy: 0.1123 - 7s/epoch - 204ms/step\n",
            "32/32 - 8s - loss: 5.8056 - accuracy: 0.1310 - val_loss: 6.2318 - val_accuracy: 0.1162 - 8s/epoch - 259ms/step\n",
            "32/32 - 6s - loss: 5.8672 - accuracy: 0.1370 - val_loss: 6.1798 - val_accuracy: 0.1155 - 6s/epoch - 199ms/step\n",
            "32/32 - 6s - loss: 5.8216 - accuracy: 0.1380 - val_loss: 6.1713 - val_accuracy: 0.1147 - 6s/epoch - 173ms/step\n",
            "32/32 - 6s - loss: 5.8923 - accuracy: 0.1460 - val_loss: 6.1237 - val_accuracy: 0.1154 - 6s/epoch - 176ms/step\n",
            "32/32 - 6s - loss: 6.0059 - accuracy: 0.1360 - val_loss: 6.1236 - val_accuracy: 0.1136 - 6s/epoch - 176ms/step\n",
            "32/32 - 6s - loss: 5.9374 - accuracy: 0.1280 - val_loss: 6.1562 - val_accuracy: 0.1153 - 6s/epoch - 172ms/step\n",
            "32/32 - 6s - loss: 5.7570 - accuracy: 0.1550 - val_loss: 6.1798 - val_accuracy: 0.1180 - 6s/epoch - 177ms/step\n",
            "32/32 - 6s - loss: 5.8968 - accuracy: 0.1380 - val_loss: 6.1611 - val_accuracy: 0.1189 - 6s/epoch - 180ms/step\n",
            "32/32 - 6s - loss: 6.0000 - accuracy: 0.1310 - val_loss: 6.1697 - val_accuracy: 0.1109 - 6s/epoch - 174ms/step\n",
            "32/32 - 6s - loss: 5.8494 - accuracy: 0.1540 - val_loss: 6.1425 - val_accuracy: 0.1193 - 6s/epoch - 181ms/step\n",
            "32/32 - 6s - loss: 5.9807 - accuracy: 0.1290 - val_loss: 6.1304 - val_accuracy: 0.1162 - 6s/epoch - 181ms/step\n",
            "7/7 - 5s - loss: 6.0671 - accuracy: 0.1089 - val_loss: 6.1400 - val_accuracy: 0.1162 - 5s/epoch - 749ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('model_en.h5')\n",
        "# model.save('model_fr.h5')"
      ],
      "metadata": {
        "id": "IvnRwW8E2dg_"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Loading the model for calcualting probablity on text data"
      ],
      "metadata": {
        "id": "UrJotkeiPAiA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = keras.models.load_model('model_en.h5')\n",
        "print(model.summary())"
      ],
      "metadata": {
        "id": "Zt--80HvO_r1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1d1dda82-02a0-43cb-c2f1-eff2faac3d86"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       (None, 10, 50)            303050    \n",
            "                                                                 \n",
            " lstm (LSTM)                 (None, 10, 100)           60400     \n",
            "                                                                 \n",
            " lstm_1 (LSTM)               (None, 100)               80400     \n",
            "                                                                 \n",
            " dense (Dense)               (None, 100)               10100     \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 6061)              612161    \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,066,111\n",
            "Trainable params: 1,066,111\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_perplexity_of_text(model,X):\n",
        "  y_prob = []\n",
        "  for x in X:\n",
        "    x = x.reshape((1,10))\n",
        "    y_pred = model.predict(x)\n",
        "    y_pred = y_pred.flatten()\n",
        "    y_prob.append(max(y_pred))\n",
        "  return y_prob\n",
        "\n",
        "def save_perplex_of_sen(filename,sequences,y_prob):\n",
        "  total_perplex = 0\n",
        "  for seq,y_ in zip(sequences,y_prob):\n",
        "    temp_perplex = (1/y_)**(0.1)\n",
        "    total_perplex += temp_perplex\n",
        "    filename.write(seq+\"\\t\"+str(temp_perplex)+\"\\n\")\n",
        "  filename.write(\"Average perplexity for text data is : \"+str(total_perplex/len(y_prob))+\"\\n\")\n",
        "  return total_perplex/len(y_prob)"
      ],
      "metadata": {
        "id": "g5XxUjrJR35_"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_prob = calculate_perplexity_of_text(model,X_test)"
      ],
      "metadata": {
        "id": "0JEqyCUNIvcQ"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "testfile = open('test-perplexity_en.txt','w+')\n",
        "avg_perplex = save_perplex_of_sen(testfile,test_seq,y_prob)\n",
        "print(\"Average perplexity of test text : \",avg_perplex)"
      ],
      "metadata": {
        "id": "MtWNHWNVbCL0"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = X_train[:30000]\n",
        "train_seq = train_seq[:30000]"
      ],
      "metadata": {
        "id": "X0r4cEKhRI36"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.shape,X_test.shape,len(train_seq)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u9fVIm7LOKDC",
        "outputId": "90a8189a-7dd4-47f6-93ce-dfe4c41ad2f1"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((30000, 10), (27428, 10), 30000)"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_prob = calculate_perplexity_of_text(model,X_train)"
      ],
      "metadata": {
        "id": "lWzGW-ZThHmX"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainfile = open('train-perplexity_en.txt','w+')\n",
        "avg_perplex = save_perplex_of_sen(trainfile,train_seq,y_prob)\n",
        "print(\"Average perplexity of train text : \",avg_perplex)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "noYi6cM-jvfm",
        "outputId": "745104d2-26c1-4516-e7a1-cb86ef9057fa"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average perplexity of train text : 1.2643583276802925\n"
          ]
        }
      ]
    }
  ]
}